{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import lzma\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_columns = ['tumor_size_cm_preTrt_preSurgery', \n",
    "                     'tumor_size_cm_secondAxis_preTrt_preSurgery', \n",
    "                     'preTrt_lymph_node_status', \n",
    "                     'preTrt_totalLymphNodes', \n",
    "                     'preTrt_numPosLymphNodes', \n",
    "                     'hist_grade', \n",
    "                     'nuclear_grade_preTrt', \n",
    "                     'age', 'race', 'menopausal_status', 'surgery_type', 'intarvenous', 'intramuscular', 'oral', \n",
    "                     'radiotherapyClass', 'chemotherapyClass', 'hormone_therapyClass', 'postmenopausal_only',\n",
    "                     'immediate_biol_target', 'anthracycline', 'taxane', 'anti_estrogen', 'aromatase_inhibitor',\n",
    "                     'estrogen_receptor_blocker', 'estrogen_receptor_blocker_and_stops_production', \n",
    "                     'estrogen_receptor_blocker_and_eliminator', 'anti_HER2', \n",
    "                     'tamoxifen', 'doxorubicin', \n",
    "                     'epirubicin', 'docetaxel', 'capecitabine', 'fluorouracil',\n",
    "                     'paclitaxel', 'cyclophosphamide', 'anastrozole', \n",
    "                     'fulvestrant', 'gefitinib', 'trastuzumab', 'letrozole', 'chemotherapy', 'hormone_therapy',\n",
    "                     'no_treatment', 'methotrexate', 'cetuximab', 'carboplatin', 'other', 'taxaneGeneral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data_dir = '/home/noskill/projects/cancer/data'\n",
    "dump_dir = os.path.join(cancer_data_dir, 'bcDump/example15bmc')\n",
    "clinical_table_path = os.path.join(cancer_data_dir, 'bcClinicalTable.csv')\n",
    "merged_path = os.path.join(dump_dir, 'ex15bmcMerged.csv.xz')\n",
    "bmc_all_path = os.path.join(dump_dir, 'bmc15mldata1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {'DFS': pandas.Int64Dtype(),\n",
    "         'pCR': pandas.Int64Dtype(),\n",
    "         'RFS': pandas.Int64Dtype(), \n",
    "         'DFS': pandas.Int64Dtype(), \n",
    "         'posOutcome': pandas.Int64Dtype()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertors for mapping string data to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_surgery(x, surgery_mapping=dict()):\n",
    "    if x not in surgery_mapping:\n",
    "        surgery_mapping[x] = len(surgery_mapping) + 1\n",
    "    return surgery_mapping[x]\n",
    "\n",
    "\n",
    "def convert_node_status(x, mapping=dict()):\n",
    "    if x == 'NA' or x == 'NaN':\n",
    "        return numpy.nan\n",
    "    if not isinstance(x, str) and numpy.isnan(x):\n",
    "        return x\n",
    "    if x not in mapping:\n",
    "        mapping[x] = len(mapping) + 1\n",
    "    return mapping[x]\n",
    "\n",
    "\n",
    "def convert_race(x, mapping=dict()):\n",
    "    return convert_node_status(x, mapping)\n",
    "\n",
    "def convert_menapause(x, mapping=dict()):\n",
    "    return convert_node_status(x, mapping)\n",
    "\n",
    "converters=dict(preTrt_lymph_node_status=convert_node_status,\n",
    "               race=convert_race,\n",
    "               menopausal_status=convert_menapause,\n",
    "               surgery_type=convert_surgery,\n",
    "               surgery=convert_surgery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load averaged treatment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc = pandas.read_csv(bmc_all_path, dtype=dtype, converters=converters)\n",
    "bmc = bmc.sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load detailed treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = pandas.read_csv(clinical_table_path, converters=converters).sort_values(by='patient_ID')\n",
    "treatment = treatment[treatment.patient_ID.isin(bmc.patient_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load genes expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = pandas.read_csv(lzma.open(merged_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features = gene_expression[gene_expression.patient_ID.isin(bmc.patient_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features = genes_features.sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# columns to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_treatment_columns = ['radio', 'surgery', 'chemo', 'hormone']\n",
    "label_columns = ['pCR', 'RFS', 'DFS', 'posOutcome']\n",
    "label_columns = ['posOutcome']\n",
    "feature_columns = genes_features.columns.to_list()[1:] + treatment_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge genes expression + averaged treatment + detailed treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pandas.merge(genes_features, bmc, left_on='patient_ID', right_on='patient_ID')\n",
    "merged = pandas.merge(merged, treatment, left_on='patient_ID', right_on='patient_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_study(study_name=None):\n",
    "    \"\"\"\n",
    "    Split one study out for cross-validation\n",
    "    \"\"\"\n",
    "    for eval_study in set(bmc.study):\n",
    "        if study_name:\n",
    "            eval_study = study_name\n",
    "        print(eval_study)\n",
    "        bmc_train = bmc[bmc.study != eval_study]\n",
    "        bmc_val = bmc[bmc.study == eval_study]\n",
    "        assert (not set(bmc_train.patient_ID).intersection(set(bmc_val.patient_ID)))\n",
    "\n",
    "        train_split = merged[merged.patient_ID.isin(bmc_train.patient_ID)]\n",
    "        val_split = merged[merged.patient_ID.isin(bmc_val.patient_ID)]\n",
    "        assert val_split.patient_ID.to_list() == bmc_val.patient_ID.to_list()\n",
    "        train_data = train_split[feature_columns].to_numpy()\n",
    "        train_labels = train_split[label_columns].to_numpy().astype(int)\n",
    "        val_data = val_split[feature_columns].to_numpy()\n",
    "        val_labels = val_split[label_columns].to_numpy().astype(int)\n",
    "        yield train_data, train_labels, val_data, val_labels\n",
    "        if study_name:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_balanced_idx(study, num):\n",
    "    if not num % 2 == 0:\n",
    "        num = num + 1\n",
    "    validation = []\n",
    "    pos_outcome = study[study.posOutcome == 1].patient_ID\n",
    "    neg_outcome = study[study.posOutcome == 0].patient_ID\n",
    "    pos_idx = numpy.arange(len(pos_outcome))\n",
    "    neg_idx = numpy.arange(len(neg_outcome))\n",
    "    random.shuffle(pos_idx)\n",
    "    random.shuffle(neg_idx)\n",
    "    i = 0\n",
    "    while not (len(validation) >= num):\n",
    "        validation.append(pos_outcome.iloc[pos_idx[i]])\n",
    "        validation.append(neg_outcome.iloc[neg_idx[i]])\n",
    "        i += 1\n",
    "    train = study[~study.patient_ID.isin(validation)]\n",
    "    validation = study[study.patient_ID.isin(validation)]\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(ratio=0.1, study_name=None, rand=False):\n",
    "    \"\"\"\n",
    "    Split dataset into train and validation sets:\n",
    "    --------------\n",
    "    Returns: train_data, train_labels, val_data, val_labels, expected\n",
    "        expected - confusion matrix expected from classification by ratio of positive/negative for each study\n",
    "    \"\"\"\n",
    "    val_patients = []\n",
    "    train_patients = []\n",
    "    expected = dict()\n",
    "    expected['TN'] = 0\n",
    "    expected['FN'] = 0\n",
    "    expected['FP'] = 0\n",
    "    expected['TP'] = 0\n",
    "    for eval_study in set(bmc.study):\n",
    "        if study_name is not None:\n",
    "            if study_name != eval_study:\n",
    "                continue\n",
    "        study = bmc[bmc.study == eval_study]\n",
    "        num_select = math.ceil(len(study) * ratio)\n",
    "        study_patients = bmc[bmc.study == eval_study]\n",
    "        bmc_train, bmc_val = select_balanced_idx(study_patients, num_select)\n",
    "        pos_prob_train = bmc_train.posOutcome.sum() / len(bmc_train)\n",
    "        neg_prob_train = 1 - pos_prob_train\n",
    "        P = bmc_val.posOutcome.sum()\n",
    "        N = len(bmc_val) - P\n",
    "        TN = N * neg_prob_train\n",
    "        TP= P * pos_prob_train\n",
    "        FP = N - TN\n",
    "        FN = P - TP\n",
    "        expected['TN'] += TN\n",
    "        expected['TP'] += TP\n",
    "        expected['FP'] += FP\n",
    "        expected['FN'] += FN\n",
    "        val_patients += bmc_val.patient_ID.to_list()\n",
    "        train_patients += bmc_train.patient_ID.to_list()\n",
    "        \n",
    "    train_split = merged[merged.patient_ID.isin(train_patients)]\n",
    "    val_split = merged[merged.patient_ID.isin(val_patients)]\n",
    "    train_data = train_split[feature_columns].to_numpy()\n",
    "    train_labels = train_split[label_columns].to_numpy().astype(int).ravel()\n",
    "    val_data = val_split[feature_columns].to_numpy()\n",
    "    val_labels = val_split[label_columns].to_numpy().astype(int).ravel()\n",
    "    if rand:\n",
    "        train_data = numpy.random.randn(*train_data.shape)\n",
    "        val_data = numpy.random.randn(*val_data.shape)\n",
    "    return train_data, train_labels, val_data, val_labels, expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(result, y_true, y_pred, x_true, x_pred):\n",
    "    result['recall'].append(recall_score(y_true, y_pred))\n",
    "    result['precision'].append( precision_score(y_true, y_pred))\n",
    "    result['f1'].append(f1_score(y_true, y_pred))\n",
    "    result['confusion'].append(confusion_matrix(y_true, y_pred))\n",
    "    result['train_f1'].append(f1_score(x_true, x_pred))\n",
    "    result['train_confusion'].append(confusion_matrix(x_true, x_pred))\n",
    "    confusion = result['confusion'][-1]\n",
    "    accuracy = (confusion[0][0] + confusion[1][1]) / (sum(confusion[0]) + sum(confusion[1]))\n",
    "    result['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(list)\n",
    "model = CatBoostClassifier(iterations=3600,\n",
    "                           depth=4,\n",
    "                           use_best_model=True,\n",
    "                           learning_rate=0.015,\n",
    "                           loss_function='Logloss',\n",
    "                           model_size_reg=2,\n",
    "                           verbose=True,\n",
    "                           scale_pos_weight=0.605,\n",
    "                           l2_leaf_reg=2,\n",
    "                           od_type='Iter', od_wait=200)\n",
    "train_data, train_labels, val_data, val_labels, expected = random_split()\n",
    "catboost_pool = Pool(train_data, \n",
    "                    train_labels)\n",
    "\n",
    "test_data = Pool(val_data,\n",
    "                 val_labels) \n",
    "# train the model\n",
    "clf = model.fit(train_data, train_labels, \n",
    "          eval_set=test_data,\n",
    "          save_snapshot=False, snapshot_file='vasya')\n",
    "y_pred = clf.predict(val_data)\n",
    "x_pred = clf.predict(train_data)\n",
    "compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "svm_total = defaultdict(list)\n",
    "model = svm.SVC(C=1, kernel='rbf', class_weight={1: 0.5})\n",
    "train_data, train_labels, val_data, val_labels, expected = random_split()\n",
    "# train the model\n",
    "clf = model.fit(numpy.nan_to_num(train_data), numpy.nan_to_num(train_labels))\n",
    "y_pred = clf.predict(numpy.nan_to_num(val_data))\n",
    "x_pred = clf.predict(numpy.nan_to_num(train_data))\n",
    "compute_metrics(svm_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in svm_total:\n",
    "    print('{0}: {1}'.format(key, svm_total[key][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - single study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "svm_total = defaultdict(list)\n",
    "\n",
    "for study in set(bmc.study):\n",
    "    print(study)\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split(ratio=0.1, study_name=study, rand=False)\n",
    "    model = svm.SVC(C=1, kernel='rbf', class_weight={1: (1 - numpy.mean(train_labels))  / numpy.mean(train_labels)})\n",
    "    # train the model\n",
    "    clf = model.fit(numpy.nan_to_num(train_data), numpy.nan_to_num(train_labels))\n",
    "    y_pred = clf.predict(numpy.nan_to_num(val_data))\n",
    "    print(y_pred)\n",
    "    x_pred = clf.predict(numpy.nan_to_num(train_data))\n",
    "    compute_metrics(svm_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in svm_total:\n",
    "    ave = numpy.asarray(svm_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nearest neigbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels, expected = random_split()\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_data, validation_data, train_labels):\n",
    "    tmp = []\n",
    "    for i in range(len(validation_data)):\n",
    "        diff = train_data - validation_data[i]\n",
    "        idx = numpy.argmin(numpy.sqrt(numpy.sum(diff ** 2, axis=1)))\n",
    "        tmp.append(idx)\n",
    "    return train_labels[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(numpy.nan_to_num(train_data), numpy.nan_to_num(val_data), train_labels)\n",
    "x_pred = predict(numpy.nan_to_num(train_data), numpy.nan_to_num(train_data), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_total = defaultdict(list)\n",
    "compute_metrics(nearest_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in nearest_total:\n",
    "    print('{0}: {1}'.format(key, nearest_total[key][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencog.atomspace import AtomSpace\n",
    "from opencog.pymoses import moses\n",
    "from opencog.scheme_wrapper import scheme_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels = next(split('study_16446_GPL570_all-bmc15'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = numpy.concatenate([train_labels, train_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[:,[0, 2]] = input_data[:,[2,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(0, 179) / max(107, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = moses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mos.run(input=input_data, python=True, args='--balance=1 -m 100000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = moses()\n",
    "input_data = [[0, 0, 0], [1, 1, 0], [1, 0, 1], [2, 1, 1]]\n",
    "output = mos.run(input=input_data, python=True)\n",
    "print (output[0].score) # Prints: 0\n",
    "model = output[0].eval\n",
    "print(model([0, 1]))  # Returns: True\n",
    "print(model([1, 1]))  # Returns: False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
