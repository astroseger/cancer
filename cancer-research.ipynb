{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3/dist-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import lzma\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5943d1bfe3f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data_dir = '/home/noskill/projects/cancer/data'\n",
    "dump_dir = os.path.join(cancer_data_dir, 'bcDump/example15bmc')\n",
    "clinical_table_path = os.path.join(cancer_data_dir, 'bcClinicalTable.csv')\n",
    "merged_path = os.path.join(dump_dir, 'ex15bmcMerged.csv.xz')\n",
    "bmc_all_path = os.path.join(dump_dir, 'bmc15mldata1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {'DFS': pandas.Int64Dtype(),\n",
    "         'pCR': pandas.Int64Dtype(),\n",
    "         'RFS': pandas.Int64Dtype(), \n",
    "         'DFS': pandas.Int64Dtype(), \n",
    "         'posOutcome': pandas.Int64Dtype()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertors for mapping string data to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_surgery(x, surgery_mapping=dict()):\n",
    "    if x not in surgery_mapping:\n",
    "        surgery_mapping[x] = len(surgery_mapping)# + 1\n",
    "    return surgery_mapping[x]\n",
    "\n",
    "\n",
    "def convert_node_status(x, mapping=dict()):\n",
    "    if x == 'NA' or x == 'NaN':\n",
    "        return numpy.nan\n",
    "    if not isinstance(x, str) and numpy.isnan(x):\n",
    "        return x\n",
    "    if x not in mapping:\n",
    "        mapping[x] = len(mapping) + 1\n",
    "    return mapping[x]\n",
    "\n",
    "\n",
    "def convert_race(x, mapping=dict()):\n",
    "    return convert_node_status(x, mapping)\n",
    "\n",
    "def convert_menapause(x, mapping=dict()):\n",
    "    return convert_node_status(x, mapping)\n",
    "\n",
    "converters=dict(preTrt_lymph_node_status=convert_node_status,\n",
    "               race=convert_race,\n",
    "               menopausal_status=convert_menapause,\n",
    "               surgery_type=convert_surgery,\n",
    "               surgery=convert_surgery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load averaged treatment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc = pandas.read_csv(bmc_all_path, dtype=dtype, converters=converters)\n",
    "bmc = bmc.sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load detailed treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = pandas.read_csv(clinical_table_path, converters=converters).sort_values(by='patient_ID')\n",
    "treatment = treatment[treatment.patient_ID.isin(bmc.patient_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study</th>\n",
       "      <th>patient_ID</th>\n",
       "      <th>radio</th>\n",
       "      <th>surgery</th>\n",
       "      <th>chemo</th>\n",
       "      <th>hormone</th>\n",
       "      <th>pCR</th>\n",
       "      <th>RFS</th>\n",
       "      <th>DFS</th>\n",
       "      <th>posOutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>study_1379_GPL1223_all-bmc15</td>\n",
       "      <td>22449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>study_1379_GPL1223_all-bmc15</td>\n",
       "      <td>22450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>study_1379_GPL1223_all-bmc15</td>\n",
       "      <td>22451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>study_1379_GPL1223_all-bmc15</td>\n",
       "      <td>22452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>study_1379_GPL1223_all-bmc15</td>\n",
       "      <td>22453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          study  patient_ID  radio  surgery  chemo  hormone  \\\n",
       "0  study_1379_GPL1223_all-bmc15       22449      0        0      0        1   \n",
       "1  study_1379_GPL1223_all-bmc15       22450      0        0      0        1   \n",
       "2  study_1379_GPL1223_all-bmc15       22451      0        0      0        1   \n",
       "3  study_1379_GPL1223_all-bmc15       22452      0        0      0        1   \n",
       "4  study_1379_GPL1223_all-bmc15       22453      0        0      0        1   \n",
       "\n",
       "    pCR   RFS  DFS  posOutcome  \n",
       "0  <NA>  <NA>    0           0  \n",
       "1  <NA>  <NA>    0           0  \n",
       "2  <NA>  <NA>    0           0  \n",
       "3  <NA>  <NA>    0           0  \n",
       "4  <NA>  <NA>    1           1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load genes expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = pandas.read_csv(lzma.open(merged_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_ID</th>\n",
       "      <th>MAGEA12</th>\n",
       "      <th>MAGEA11</th>\n",
       "      <th>KLF1</th>\n",
       "      <th>ADH7</th>\n",
       "      <th>MSH4</th>\n",
       "      <th>BIRC3</th>\n",
       "      <th>AKR1C4</th>\n",
       "      <th>GBX2</th>\n",
       "      <th>GCGR</th>\n",
       "      <th>...</th>\n",
       "      <th>ZNF80</th>\n",
       "      <th>ZNF83</th>\n",
       "      <th>ZNF84</th>\n",
       "      <th>ZNF91</th>\n",
       "      <th>ZNHIT2</th>\n",
       "      <th>ZSCAN2</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22449</td>\n",
       "      <td>-0.118953</td>\n",
       "      <td>1.180345</td>\n",
       "      <td>0.252643</td>\n",
       "      <td>-0.262987</td>\n",
       "      <td>0.142903</td>\n",
       "      <td>0.167314</td>\n",
       "      <td>0.498846</td>\n",
       "      <td>0.774632</td>\n",
       "      <td>0.104353</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.564143</td>\n",
       "      <td>0.466733</td>\n",
       "      <td>0.827552</td>\n",
       "      <td>-0.617981</td>\n",
       "      <td>0.303161</td>\n",
       "      <td>1.260602</td>\n",
       "      <td>-0.217995</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>0.389849</td>\n",
       "      <td>1.313703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22450</td>\n",
       "      <td>0.423693</td>\n",
       "      <td>-0.922374</td>\n",
       "      <td>-1.202192</td>\n",
       "      <td>-0.105451</td>\n",
       "      <td>-0.061571</td>\n",
       "      <td>-0.093231</td>\n",
       "      <td>-0.095550</td>\n",
       "      <td>-0.481403</td>\n",
       "      <td>-0.214238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711752</td>\n",
       "      <td>0.358388</td>\n",
       "      <td>0.037911</td>\n",
       "      <td>2.304784</td>\n",
       "      <td>0.328942</td>\n",
       "      <td>-1.028791</td>\n",
       "      <td>-0.850002</td>\n",
       "      <td>-0.292574</td>\n",
       "      <td>-0.068982</td>\n",
       "      <td>0.722123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22451</td>\n",
       "      <td>-0.239183</td>\n",
       "      <td>-0.733389</td>\n",
       "      <td>0.523791</td>\n",
       "      <td>-0.081958</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>-0.008094</td>\n",
       "      <td>0.268636</td>\n",
       "      <td>-0.614192</td>\n",
       "      <td>0.027471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011786</td>\n",
       "      <td>-0.474762</td>\n",
       "      <td>-0.349981</td>\n",
       "      <td>-0.097197</td>\n",
       "      <td>0.100946</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>-0.367363</td>\n",
       "      <td>0.094464</td>\n",
       "      <td>-0.372665</td>\n",
       "      <td>-0.790771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22452</td>\n",
       "      <td>0.500445</td>\n",
       "      <td>-0.177686</td>\n",
       "      <td>-0.216638</td>\n",
       "      <td>-0.130850</td>\n",
       "      <td>-0.261039</td>\n",
       "      <td>-0.048521</td>\n",
       "      <td>1.479664</td>\n",
       "      <td>-0.100120</td>\n",
       "      <td>0.233178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757255</td>\n",
       "      <td>0.590212</td>\n",
       "      <td>0.060150</td>\n",
       "      <td>2.287583</td>\n",
       "      <td>-0.108866</td>\n",
       "      <td>-1.132500</td>\n",
       "      <td>-0.106976</td>\n",
       "      <td>-0.216267</td>\n",
       "      <td>0.393671</td>\n",
       "      <td>-0.027349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22453</td>\n",
       "      <td>-0.609235</td>\n",
       "      <td>0.259494</td>\n",
       "      <td>-0.071802</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>0.162509</td>\n",
       "      <td>0.112654</td>\n",
       "      <td>-0.239435</td>\n",
       "      <td>0.229737</td>\n",
       "      <td>-0.132271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407159</td>\n",
       "      <td>0.570637</td>\n",
       "      <td>0.851658</td>\n",
       "      <td>-0.412950</td>\n",
       "      <td>0.105692</td>\n",
       "      <td>-1.047445</td>\n",
       "      <td>0.084480</td>\n",
       "      <td>-0.224081</td>\n",
       "      <td>-0.021074</td>\n",
       "      <td>0.764555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_ID   MAGEA12   MAGEA11      KLF1      ADH7      MSH4     BIRC3  \\\n",
       "0       22449 -0.118953  1.180345  0.252643 -0.262987  0.142903  0.167314   \n",
       "1       22450  0.423693 -0.922374 -1.202192 -0.105451 -0.061571 -0.093231   \n",
       "2       22451 -0.239183 -0.733389  0.523791 -0.081958 -0.004635 -0.008094   \n",
       "3       22452  0.500445 -0.177686 -0.216638 -0.130850 -0.261039 -0.048521   \n",
       "4       22453 -0.609235  0.259494 -0.071802  0.027963  0.162509  0.112654   \n",
       "\n",
       "     AKR1C4      GBX2      GCGR  ...     ZNF80     ZNF83     ZNF84     ZNF91  \\\n",
       "0  0.498846  0.774632  0.104353  ... -1.564143  0.466733  0.827552 -0.617981   \n",
       "1 -0.095550 -0.481403 -0.214238  ...  0.711752  0.358388  0.037911  2.304784   \n",
       "2  0.268636 -0.614192  0.027471  ... -0.011786 -0.474762 -0.349981 -0.097197   \n",
       "3  1.479664 -0.100120  0.233178  ...  0.757255  0.590212  0.060150  2.287583   \n",
       "4 -0.239435  0.229737 -0.132271  ...  0.407159  0.570637  0.851658 -0.412950   \n",
       "\n",
       "     ZNHIT2    ZSCAN2      ZXDC       ZYX     ZZEF1      ZZZ3  \n",
       "0  0.303161  1.260602 -0.217995  0.219529  0.389849  1.313703  \n",
       "1  0.328942 -1.028791 -0.850002 -0.292574 -0.068982  0.722123  \n",
       "2  0.100946 -0.554700 -0.367363  0.094464 -0.372665 -0.790771  \n",
       "3 -0.108866 -1.132500 -0.106976 -0.216267  0.393671 -0.027349  \n",
       "4  0.105692 -1.047445  0.084480 -0.224081 -0.021074  0.764555  \n",
       "\n",
       "[5 rows x 8833 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expression.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features = gene_expression[gene_expression.patient_ID.isin(bmc.patient_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features = genes_features.sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# columns to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam50 = \"\"\"ACTR3B\n",
    "ANLN\n",
    "BAG1\n",
    "BCL2\n",
    "BIRC5\n",
    "BLVRA\n",
    "CCNB1\n",
    "CCNE1\n",
    "CDC20\n",
    "CDC6\n",
    "NUF2\n",
    "CDH3\n",
    "CENPF\n",
    "CEP55\n",
    "CXXC5\n",
    "EGFR\n",
    "ERBB2\n",
    "ESR1\n",
    "EXO1\n",
    "FGFR4\n",
    "FOXA1\n",
    "FOXC1\n",
    "GPR160\n",
    "GRB7\n",
    "KIF2C\n",
    "NDC80\n",
    "KRT14\n",
    "KRT17\n",
    "KRT5\n",
    "MAPT\n",
    "MDM2\n",
    "MELK\n",
    "MIA\n",
    "MKI67\n",
    "MLPH\n",
    "MMP11\n",
    "MYBL2\n",
    "MYC\n",
    "NAT1\n",
    "ORC6\n",
    "PGR\n",
    "PHGDH\n",
    "PTTG1\n",
    "RRM2\n",
    "SFRP1\n",
    "SLC39A6\n",
    "TMEM45B\n",
    "TYMS\n",
    "UBE2C\n",
    "UBE2T\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_columns = ['tumor_size_cm_preTrt_preSurgery', \n",
    "                     'preTrt_lymph_node_status', \n",
    "                     'preTrt_totalLymphNodes', \n",
    "                     'preTrt_numPosLymphNodes', \n",
    "                     'hist_grade', \n",
    "                     'nuclear_grade_preTrt', \n",
    "                     'age', 'race', 'menopausal_status', 'surgery_type', 'intarvenous', 'intramuscular', 'oral', \n",
    "                     'radiotherapyClass', 'chemotherapyClass', 'hormone_therapyClass', 'postmenopausal_only', \n",
    "                     'anthracycline', 'taxane', 'anti_estrogen', 'aromatase_inhibitor',\n",
    "                     'estrogen_receptor_blocker', 'estrogen_receptor_blocker_and_stops_production', 'anti_HER2', \n",
    "                     'tamoxifen', 'doxorubicin', \n",
    "                     'epirubicin', 'docetaxel', 'capecitabine', 'fluorouracil',\n",
    "                     'paclitaxel', 'cyclophosphamide', 'anastrozole',\n",
    "                     'trastuzumab', 'letrozole', 'chemotherapy',\n",
    "                     'no_treatment', 'methotrexate', 'other', 'taxaneGeneral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam50col = genes_features.columns[genes_features.columns.isin(pam50).nonzero()[0]].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_treatment_columns = ['radio', 'surgery', 'chemo', 'hormone']\n",
    "label_columns = ['pCR', 'RFS', 'DFS', 'posOutcome']\n",
    "label_columns = ['posOutcome']\n",
    "genes_columns = genes_features.columns.to_list()[1:]\n",
    "feature_columns = genes_columns + treatment_columns # label_columns +  # pam50col #  +   + aggregated_treatment_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge genes expression + averaged treatment + detailed treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pandas.merge(genes_features, bmc, left_on='patient_ID', right_on='patient_ID')\n",
    "merged = pandas.merge(merged, treatment, left_on='patient_ID', right_on='patient_ID')\n",
    "merged.insert(0, 'row_num', range(0,len(merged)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_study(study_name=None):\n",
    "    \"\"\"\n",
    "    Split one study out for cross-validation\n",
    "    \"\"\"\n",
    "    for eval_study in set(bmc.study):\n",
    "        if study_name:\n",
    "            eval_study = study_name\n",
    "        print(eval_study)\n",
    "        bmc_train = bmc[bmc.study != eval_study]\n",
    "        bmc_val = bmc[bmc.study == eval_study]\n",
    "        assert (not set(bmc_train.patient_ID).intersection(set(bmc_val.patient_ID)))\n",
    "\n",
    "        train_split = merged[merged.patient_ID.isin(bmc_train.patient_ID)]\n",
    "        val_split = merged[merged.patient_ID.isin(bmc_val.patient_ID)]\n",
    "        assert val_split.patient_ID.to_list() == bmc_val.patient_ID.to_list()\n",
    "        train_data = train_split[feature_columns].to_numpy()\n",
    "        train_labels = train_split[label_columns].to_numpy().astype(int)\n",
    "        val_data = val_split[feature_columns].to_numpy()\n",
    "        val_labels = val_split[label_columns].to_numpy().astype(int)\n",
    "        yield train_data, train_labels, val_data, val_labels\n",
    "        if study_name:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_balanced_idx(study, num):\n",
    "    if not num % 2 == 0:\n",
    "        num = num + 1\n",
    "    validation = []\n",
    "    pos_outcome = study[study.posOutcome == 1].patient_ID\n",
    "    neg_outcome = study[study.posOutcome == 0].patient_ID\n",
    "    pos_idx = numpy.arange(len(pos_outcome))\n",
    "    neg_idx = numpy.arange(len(neg_outcome))\n",
    "    random.shuffle(pos_idx)\n",
    "    random.shuffle(neg_idx)\n",
    "    i = 0\n",
    "    while not (len(validation) >= num):\n",
    "        validation.append(pos_outcome.iloc[pos_idx[i]])\n",
    "        validation.append(neg_outcome.iloc[neg_idx[i]])\n",
    "        i += 1\n",
    "    train = study[~study.patient_ID.isin(validation)]\n",
    "    validation = study[study.patient_ID.isin(validation)]\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_patients_by_study(study_patients: Dict[str, list]) -> Dict[str, list]:\n",
    "    result = defaultdict(list)\n",
    "    max_length = max([len(x) for x in study_patients.values()])\n",
    "    for study, lst in study_patients.items():\n",
    "        result[study] += lst\n",
    "        to_upsample = max_length - len(lst)\n",
    "        result[study] += [random.choice(lst) for i in range(to_upsample)]\n",
    "    assert all([(len(x) == max_length) for x in result.values()])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc(patient_ID, frame):\n",
    "    return frame[frame.patient_ID == patient_ID].row_num.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(ratio=0.1, study_name=None, rand=False, to_numpy=True, balance_by_study=False):\n",
    "    \"\"\"\n",
    "    Split dataset into train and validation sets:\n",
    "    --------------\n",
    "    Returns: train_data, train_labels, val_data, val_labels, expected\n",
    "        expected - confusion matrix expected from classification by ratio of positive/negative for each study\n",
    "    \"\"\"\n",
    "    val_dict = defaultdict(list)\n",
    "    train_dict = defaultdict(list)\n",
    "    expected = dict()\n",
    "    expected['TN'] = 0\n",
    "    expected['FN'] = 0\n",
    "    expected['FP'] = 0\n",
    "    expected['TP'] = 0\n",
    "    \n",
    "    for eval_study in set(bmc.study):\n",
    "        if study_name is not None:\n",
    "            if study_name != eval_study:\n",
    "                continue\n",
    "        study = bmc[bmc.study == eval_study]\n",
    "        num_select = math.ceil(len(study) * ratio)\n",
    "        study_patients = bmc[bmc.study == eval_study]\n",
    "        bmc_train, bmc_val = select_balanced_idx(study_patients, num_select)\n",
    "        pos_prob_train = bmc_train.posOutcome.sum() / len(bmc_train)\n",
    "        neg_prob_train = 1 - pos_prob_train\n",
    "        P = bmc_val.posOutcome.sum()\n",
    "        N = len(bmc_val) - P\n",
    "        TN = N * neg_prob_train\n",
    "        TP= P * pos_prob_train\n",
    "        FP = N - TN\n",
    "        FN = P - TP\n",
    "        expected['TN'] += TN\n",
    "        expected['TP'] += TP\n",
    "        expected['FP'] += FP\n",
    "        expected['FN'] += FN\n",
    "        val_dict[eval_study] = bmc_val.patient_ID.to_list()\n",
    "        train_dict[eval_study] = bmc_train.patient_ID.to_list()\n",
    "    if balance_by_study:\n",
    "        train_dict = resample_patients_by_study(train_dict)\n",
    "        iloc = []\n",
    "        for patient_lst in train_dict.values():\n",
    "            iloc += [get_loc(p, merged) for p in patient_lst]\n",
    "        train_split = merged.iloc[iloc]\n",
    "    else:\n",
    "        train_patients = []\n",
    "        for patient_lst in train_dict.values():\n",
    "            train_patients += patient_lst\n",
    "        train_split = merged[merged.patient_ID.isin(train_patients)]\n",
    "    val_patients = []\n",
    "    for patient_lst in val_dict.values():\n",
    "        val_patients += patient_lst\n",
    "    val_split = merged[merged.patient_ID.isin(val_patients)]\n",
    "    train_data = train_split[feature_columns]\n",
    "    train_labels = train_split[label_columns]\n",
    "    val_data = val_split[feature_columns]\n",
    "    val_labels = val_split[label_columns]\n",
    "    if rand:\n",
    "        train_data = numpy.random.randn(*train_data.shape)\n",
    "        val_data = numpy.random.randn(*val_data.shape)\n",
    "    if to_numpy:\n",
    "        train_data = train_data.to_numpy()\n",
    "        train_labels = train_labels.to_numpy().astype(int).ravel()\n",
    "        val_data = val_data.to_numpy()\n",
    "        val_labels = val_labels.to_numpy().astype(int).ravel()\n",
    "    return train_data, train_labels, val_data, val_labels, expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(result, y_true, y_pred, x_true, x_pred):\n",
    "    result['recall'].append(recall_score(y_true, y_pred))\n",
    "    result['precision'].append( precision_score(y_true, y_pred))\n",
    "    result['f1'].append(f1_score(y_true, y_pred))\n",
    "    result['confusion'].append(confusion_matrix(y_true, y_pred))\n",
    "    result['train_f1'].append(f1_score(x_true, x_pred))\n",
    "    result['train_confusion'].append(confusion_matrix(x_true, x_pred))\n",
    "    confusion = result['confusion'][-1]\n",
    "    accuracy = (confusion[0][0] + confusion[1][1]) / (sum(confusion[0]) + sum(confusion[1]))\n",
    "    result['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(list)\n",
    "model = CatBoostClassifier(iterations=3600,\n",
    "                           depth=7,\n",
    "                           use_best_model=True,\n",
    "                           learning_rate=0.005,\n",
    "                           loss_function='Logloss',\n",
    "                           model_size_reg=20,\n",
    "                           verbose=True,\n",
    "                           scale_pos_weight=0.605,\n",
    "                           l2_leaf_reg=20,\n",
    "                           od_type='Iter', od_wait=200)\n",
    "train_data, train_labels, val_data, val_labels, expected = random_split(balance_by_study=True)\n",
    "catboost_pool = Pool(train_data, \n",
    "                    train_labels)\n",
    "\n",
    "test_data = Pool(val_data,\n",
    "                 val_labels) \n",
    "# train the model\n",
    "clf = model.fit(train_data, train_labels, \n",
    "          eval_set=test_data,\n",
    "          save_snapshot=False, snapshot_file='vasya')\n",
    "y_pred = clf.predict(val_data)\n",
    "x_pred = clf.predict(train_data)\n",
    "compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "svm_total = defaultdict(list)\n",
    "for i in range(30):\n",
    "    print('iteration {0}'.format(i))\n",
    "    model = svm.SVC(C=1, kernel='rbf', class_weight={1: 0.5})\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split(balance_by_study=True)\n",
    "    # train the model\n",
    "    clf = model.fit(numpy.nan_to_num(train_data), numpy.nan_to_num(train_labels))\n",
    "    y_pred = clf.predict(numpy.nan_to_num(val_data))\n",
    "    x_pred = clf.predict(numpy.nan_to_num(train_data))\n",
    "    compute_metrics(svm_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in svm_total:\n",
    "    ave = numpy.asarray(svm_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - single study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "svm_total = defaultdict(list)\n",
    "for study in set(bmc.study):\n",
    "#     if study != 'study_25065_GPL96_MDACC-bmc15':\n",
    "#         continue\n",
    "    print('\\n' * 2 + study)\n",
    "    for i in range(20):\n",
    "        train_data, train_labels, val_data, val_labels, expected = random_split(ratio=0.1, study_name=study)\n",
    "        C = 1\n",
    "        if study == 'study_16446_GPL570_all-bmc15':\n",
    "            C = 1.5\n",
    "        if study == 'study_22358_GPL5325_all-bmc15':\n",
    "            C = 0.1\n",
    "        if study == 'study_22226_GPL1708_all-bmc15':\n",
    "            C = 2\n",
    "        if study == 'study_20181_GPL96_all-bmc15':\n",
    "            C = 0.72\n",
    "        if study == 'study_25065_GPL96_MDACC-bmc15':\n",
    "            C = 1.72\n",
    "        model = svm.SVC(C=C, kernel='rbf', class_weight={1: (1 - numpy.mean(train_labels))  / numpy.mean(train_labels)})\n",
    "        # train the model\n",
    "        clf = model.fit(numpy.nan_to_num(train_data), numpy.nan_to_num(train_labels))\n",
    "        y_pred = clf.predict(numpy.nan_to_num(val_data))\n",
    "        # print(y_pred)\n",
    "        x_pred = clf.predict(numpy.nan_to_num(train_data))\n",
    "        compute_metrics(svm_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in svm_total:\n",
    "    ave = numpy.asarray(svm_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nearest neigbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_data, validation_data, train_labels):\n",
    "    tmp = []\n",
    "    for i in range(len(validation_data)):\n",
    "        diff = train_data - validation_data[i]\n",
    "        idx = numpy.argmin(numpy.sqrt(numpy.sum(diff ** 2, axis=1)))\n",
    "        tmp.append(idx)\n",
    "    return train_labels[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_total = defaultdict(list)\n",
    "for i in range(10):\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split()\n",
    "    y_pred = predict(numpy.nan_to_num(train_data), numpy.nan_to_num(val_data), train_labels)\n",
    "    # x_pred = predict(numpy.nan_to_num(train_data), numpy.nan_to_num(train_data), train_labels)\n",
    "    compute_metrics(nearest_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "\n",
    "for key in nearest_total:\n",
    "    ave = numpy.asarray(nearest_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "train_data, train_labels, val_data, val_labels, expected = random_split(ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_total = defaultdict(list)\n",
    "for i in range(10):\n",
    "    gnb = GaussianNB()\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split()\n",
    "    model = gnb.fit(numpy.nan_to_num(train_data, nan=-1), numpy.nan_to_num(train_labels))\n",
    "    y_pred = model.predict(numpy.nan_to_num(val_data, nan=-1))\n",
    "    x_pred = model.predict(numpy.nan_to_num(train_data))\n",
    "    compute_metrics(nearest_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "\n",
    "for key in nearest_total:\n",
    "    ave = numpy.asarray(nearest_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_num</th>\n",
       "      <th>patient_ID</th>\n",
       "      <th>MAGEA12</th>\n",
       "      <th>MAGEA11</th>\n",
       "      <th>KLF1</th>\n",
       "      <th>ADH7</th>\n",
       "      <th>MSH4</th>\n",
       "      <th>BIRC3</th>\n",
       "      <th>AKR1C4</th>\n",
       "      <th>GBX2</th>\n",
       "      <th>...</th>\n",
       "      <th>chemotherapy</th>\n",
       "      <th>hormone_therapy</th>\n",
       "      <th>no_treatment</th>\n",
       "      <th>methotrexate</th>\n",
       "      <th>cetuximab</th>\n",
       "      <th>carboplatin</th>\n",
       "      <th>other</th>\n",
       "      <th>taxaneGeneral</th>\n",
       "      <th>neoadjuvant_or_adjuvant</th>\n",
       "      <th>study_specific_protocol_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22449</td>\n",
       "      <td>-0.118953</td>\n",
       "      <td>1.180345</td>\n",
       "      <td>0.252643</td>\n",
       "      <td>-0.262987</td>\n",
       "      <td>0.142903</td>\n",
       "      <td>0.167314</td>\n",
       "      <td>0.498846</td>\n",
       "      <td>0.774632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adj</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22450</td>\n",
       "      <td>0.423693</td>\n",
       "      <td>-0.922374</td>\n",
       "      <td>-1.202192</td>\n",
       "      <td>-0.105451</td>\n",
       "      <td>-0.061571</td>\n",
       "      <td>-0.093231</td>\n",
       "      <td>-0.095550</td>\n",
       "      <td>-0.481403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adj</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22451</td>\n",
       "      <td>-0.239183</td>\n",
       "      <td>-0.733389</td>\n",
       "      <td>0.523791</td>\n",
       "      <td>-0.081958</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>-0.008094</td>\n",
       "      <td>0.268636</td>\n",
       "      <td>-0.614192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adj</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22452</td>\n",
       "      <td>0.500445</td>\n",
       "      <td>-0.177686</td>\n",
       "      <td>-0.216638</td>\n",
       "      <td>-0.130850</td>\n",
       "      <td>-0.261039</td>\n",
       "      <td>-0.048521</td>\n",
       "      <td>1.479664</td>\n",
       "      <td>-0.100120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adj</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22453</td>\n",
       "      <td>-0.609235</td>\n",
       "      <td>0.259494</td>\n",
       "      <td>-0.071802</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>0.162509</td>\n",
       "      <td>0.112654</td>\n",
       "      <td>-0.239435</td>\n",
       "      <td>0.229737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>adj</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8981 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_num  patient_ID   MAGEA12   MAGEA11      KLF1      ADH7      MSH4  \\\n",
       "0        0       22449 -0.118953  1.180345  0.252643 -0.262987  0.142903   \n",
       "1        1       22450  0.423693 -0.922374 -1.202192 -0.105451 -0.061571   \n",
       "2        2       22451 -0.239183 -0.733389  0.523791 -0.081958 -0.004635   \n",
       "3        3       22452  0.500445 -0.177686 -0.216638 -0.130850 -0.261039   \n",
       "4        4       22453 -0.609235  0.259494 -0.071802  0.027963  0.162509   \n",
       "\n",
       "      BIRC3    AKR1C4      GBX2  ...  chemotherapy  hormone_therapy  \\\n",
       "0  0.167314  0.498846  0.774632  ...           0.0              0.0   \n",
       "1 -0.093231 -0.095550 -0.481403  ...           0.0              0.0   \n",
       "2 -0.008094  0.268636 -0.614192  ...           0.0              0.0   \n",
       "3 -0.048521  1.479664 -0.100120  ...           0.0              0.0   \n",
       "4  0.112654 -0.239435  0.229737  ...           0.0              0.0   \n",
       "\n",
       "   no_treatment  methotrexate  cetuximab  carboplatin  other  taxaneGeneral  \\\n",
       "0           0.0           0.0        0.0          0.0    0.0            0.0   \n",
       "1           0.0           0.0        0.0          0.0    0.0            0.0   \n",
       "2           0.0           0.0        0.0          0.0    0.0            0.0   \n",
       "3           0.0           0.0        0.0          0.0    0.0            0.0   \n",
       "4           0.0           0.0        0.0          0.0    0.0            0.0   \n",
       "\n",
       "   neoadjuvant_or_adjuvant  study_specific_protocol_number  \n",
       "0                      adj                             1.0  \n",
       "1                      adj                             1.0  \n",
       "2                      adj                             1.0  \n",
       "3                      adj                             1.0  \n",
       "4                      adj                             1.0  \n",
       "\n",
       "[5 rows x 8981 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitize_genes(col):\n",
    "    _, edges = numpy.histogram(col, bins=15, density=True)\n",
    "    res = numpy.digitize(col, edges)\n",
    "    return res - res.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns = [x for x in merged.columns[~merged.columns.isin(genes_columns)] if x in feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ar = numpy.zeros((16, 4), dtype=numpy.bool_)\n",
    "for i in range(16):\n",
    "    ar0 = bin(i).split('0b')[1]\n",
    "    ar0 = '0' * (4 - len(ar0)) + ar0\n",
    "    res_ar[i] = [int(x) for x in ar0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False],\n",
       "       [False, False,  True,  True],\n",
       "       [False,  True, False, False],\n",
       "       [False,  True, False,  True],\n",
       "       [False,  True,  True, False],\n",
       "       [False,  True,  True,  True],\n",
       "       [ True, False, False, False],\n",
       "       [ True, False, False,  True],\n",
       "       [ True, False,  True, False],\n",
       "       [ True, False,  True,  True],\n",
       "       [ True,  True, False, False],\n",
       "       [ True,  True, False,  True],\n",
       "       [ True,  True,  True, False],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_genes():\n",
    "    n_patients, n_genes = merged[genes_columns].shape\n",
    "    result = dict()\n",
    "    for gene_col in range(len(genes_columns)):\n",
    "    # for gene_col in range(1000): \n",
    "        binary_genes = numpy.zeros((n_patients, 4), dtype=numpy.bool_)\n",
    "        digitized = digitize_genes(merged[genes_columns[gene_col]])\n",
    "        for i, digit in enumerate(digitized):\n",
    "            binary_genes[i] = res_ar[digit]\n",
    "        column_names = [genes_columns[gene_col] + '_{0}'.format(x) for x in range(4)]\n",
    "        for i, col in enumerate(column_names):\n",
    "            result[col] = binary_genes[:, i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_non_genes():\n",
    "    non_genes_data = dict()\n",
    "    for oth in other_columns:\n",
    "        dig = digitize_non_genes_data(merged[oth])\n",
    "        set_size = len(set(dig))\n",
    "        new_col = -1\n",
    "        for x in range(1, 5):\n",
    "            if set_size <= 2 ** x:\n",
    "                new_col = x\n",
    "                break\n",
    "        assert new_col != -1\n",
    "        ar1 = numpy.zeros((len(merged[oth]), new_col), dtype=numpy.bool_)\n",
    "        for i, d in enumerate(dig):\n",
    "            ar1[i] = res_ar[d][-new_col:]\n",
    "        column_names = [oth + '_{0}'.format(x) for x in range(new_col)]\n",
    "        for i, col_name in enumerate(column_names):\n",
    "            non_genes_data[col_name] = ar1[:, i]\n",
    "    return non_genes_data\n",
    "\n",
    "def binarize_dataset():\n",
    "    result = dict()\n",
    "    patients_id = merged.patient_ID.to_list()\n",
    "    result['patient_ID'] = patients_id\n",
    "    result['posOutcome'] = merged.posOutcome.to_list()\n",
    "    result.update(binary_genes())\n",
    "    result.update(binary_non_genes())\n",
    "    return pandas.DataFrame(data=result).sort_values(by='patient_ID').drop(columns=['patient_ID']) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data = binarize_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 35389)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data.to_csv('/tmp/cancer_bin.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ar[0][-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[12 < 2 ** x for x in range(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitize_non_genes_data(col):\n",
    "    not_nan = numpy.nan_to_num(col, nan=-1)\n",
    "    n_unique = len(set(not_nan))\n",
    "    if 15 < n_unique:\n",
    "        n_unique = 15\n",
    "    edge = numpy.histogram_bin_edges(numpy.nan_to_num(col, nan=col.min()), bins=n_unique - 1)\n",
    "    digits = numpy.digitize(not_nan, edge)\n",
    "    digits = digits - digits.min()\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for oth in other_columns:\n",
    "    print(oth)\n",
    "    print(set(digitize_non_genes_data(merged[oth])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(numpy.nan_to_num(merged.hormone_therapy, nan=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.histogram_bin_edges(r, bins=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = numpy.histogram_bin_edges(r, bins=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencog.pyasmoses import moses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels, expected = random_split(ratio=0.1, to_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(-1)\n",
    "train_data.to_csv('/tmp/input_data.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_data.surgery_type.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = numpy.concatenate([train_labels[..., numpy.newaxis], train_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = moses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = \"--log-file log1.txt.log --hc-fraction-of-nn 0.01 -j5 --balance 1 -m 100000 --result-count 100 --reduct-knob-building-effort=2 --hc-widen-search=1 --enable-fs=1 --fs-algo=smd --fs-target-size=1000 --hc-crossover-min-neighbors=5000 --fs-focus=all --fs-seed=init  --hc-max-nn-evals=10000 --hc-crossover-pop-size=1000 -l debug --noise 0.2 -q 0.05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mos.run(input=numpy.nan_to_num(input_data), python=True, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = moses()\n",
    "input_data = [[0, 0, 0],\n",
    "              [0.2, 0.2, 0.4],\n",
    "              [1, 1, 2],\n",
    "              [1, 0, 1],\n",
    "              [2., 1, 3]]\n",
    "output = mos.run(input=input_data, python=True, args='-m 1000000 --max-time=60 --balance=1')\n",
    "print (output[0].score) # Prints: 0\n",
    "model = output[0].eval\n",
    "print(model([0, 1]))  # Returns: True\n",
    "print(model([1, 1]))  # Returns: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moses_args = []\n",
    "# target column\n",
    "moses_args.append('--problem_type=it')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
