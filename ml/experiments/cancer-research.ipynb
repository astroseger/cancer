{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3/dist-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import lzma\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data_dir = '/home/noskill/projects/cancer/data'\n",
    "dump_dir = os.path.join(cancer_data_dir, 'bcDump/example15bmc')\n",
    "clinical_table_path = os.path.join(cancer_data_dir, 'bcClinicalTable.csv')\n",
    "merged_path = os.path.join(dump_dir, 'ex15bmcMerged.csv.xz')\n",
    "bmc_all_path = os.path.join(dump_dir, 'bmc15mldata1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {'DFS': pandas.Int64Dtype(),\n",
    "         'pCR': pandas.Int64Dtype(),\n",
    "         'RFS': pandas.Int64Dtype(), \n",
    "         'DFS': pandas.Int64Dtype(), \n",
    "         'posOutcome': pandas.Int64Dtype()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load averaged treatment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc = pandas.read_csv(bmc_all_path, dtype=dtype, converters=converters)\n",
    "bmc = bmc.sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load detailed treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = pandas.read_csv(clinical_table_path, converters=converters).sort_values(by='patient_ID')\n",
    "treatment = treatment[treatment.patient_ID.isin(bmc.patient_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load genes expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression = pandas.read_csv(lzma.open(merged_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expression.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features = gene_expression[gene_expression.patient_ID.isin(bmc.patient_ID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_features = genes_features.sort_values(by='patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# columns to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam50col = genes_features.columns[genes_features.columns.isin(pam50).nonzero()[0]].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_treatment_columns = ['radio', 'surgery', 'chemo', 'hormone']\n",
    "label_columns = ['pCR', 'RFS', 'DFS', 'posOutcome']\n",
    "label_columns = ['posOutcome']\n",
    "genes_columns = genes_features.columns.to_list()[1:]\n",
    "feature_columns = xgboost_top_100 #genes_columns + treatment_columns # label_columns +  # pam50col #  +   + aggregated_treatment_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge genes expression + averaged treatment + detailed treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pandas.merge(genes_features, bmc, left_on='patient_ID', right_on='patient_ID')\n",
    "merged = pandas.merge(merged, treatment, left_on='patient_ID', right_on='patient_ID')\n",
    "merged.insert(0, 'row_num', range(0,len(merged)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(list)\n",
    "model = CatBoostClassifier(iterations=3600,\n",
    "                           depth=7,\n",
    "                           use_best_model=True,\n",
    "                           learning_rate=0.005,\n",
    "                           loss_function='Logloss',\n",
    "                           model_size_reg=20,\n",
    "                           verbose=True,\n",
    "                           scale_pos_weight=0.605,\n",
    "                           l2_leaf_reg=20,\n",
    "                           od_type='Iter', od_wait=200)\n",
    "model = CatBoostClassifier(verbose=True)\n",
    "train_data, train_labels, val_data, val_labels, expected = random_split(balance_by_study=True)\n",
    "catboost_pool = Pool(train_data, \n",
    "                    train_labels)\n",
    "\n",
    "test_data = Pool(val_data,\n",
    "                 val_labels) \n",
    "# train the model\n",
    "clf = model.fit(train_data, train_labels, \n",
    "          eval_set=test_data,\n",
    "          save_snapshot=False, snapshot_file='vasya')\n",
    "y_pred = clf.predict(val_data)\n",
    "x_pred = clf.predict(train_data)\n",
    "compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "res = defaultdict(list)\n",
    "\n",
    "for i in range(30):\n",
    "    print(i)\n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split(merged, bmc,\n",
    "                                                                           feature_columns, label_columns)\n",
    "\n",
    "    # train the model\n",
    "    clf = model.fit(train_data, train_labels,\n",
    "                    eval_set=[(train_data, train_labels), (val_data, val_labels)], \n",
    "                    early_stopping_rounds=50, verbose=False)\n",
    "    y_pred = clf.predict(val_data)\n",
    "    x_pred = clf.predict(train_data)\n",
    "    compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in res:\n",
    "    ave = numpy.asarray(res[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_booster().get_score(importance_type=\"gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_sorted = sorted([(y, x) for (x,y) in weights.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[feature_columns[int(num[1:])] for (_, num) in weights_sorted[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (w, num) in weights_sorted[:100]:\n",
    "    print(feature_columns[int(num[1:])], w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "svm_total = defaultdict(list)\n",
    "for i in range(5):\n",
    "    print('iteration {0}'.format(i))\n",
    "    model = svm.SVC(C=1, kernel='rbf', class_weight={1: 0.5})\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split()\n",
    "    # train the model\n",
    "    clf = model.fit(numpy.nan_to_num(train_data), numpy.nan_to_num(train_labels))\n",
    "    y_pred = clf.predict(numpy.nan_to_num(val_data))\n",
    "    x_pred = clf.predict(numpy.nan_to_num(train_data))\n",
    "    compute_metrics(svm_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in svm_total:\n",
    "    ave = numpy.asarray(svm_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - single study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "svm_total = defaultdict(list)\n",
    "for study in set(bmc.study):\n",
    "#     if study != 'study_25065_GPL96_MDACC-bmc15':\n",
    "#         continue\n",
    "    print('\\n' * 2 + study)\n",
    "    for i in range(20):\n",
    "        train_data, train_labels, val_data, val_labels, expected = random_split(ratio=0.1, study_name=study)\n",
    "        C = 1\n",
    "        if study == 'study_16446_GPL570_all-bmc15':\n",
    "            C = 1.5\n",
    "        if study == 'study_22358_GPL5325_all-bmc15':\n",
    "            C = 0.1\n",
    "        if study == 'study_22226_GPL1708_all-bmc15':\n",
    "            C = 2\n",
    "        if study == 'study_20181_GPL96_all-bmc15':\n",
    "            C = 0.72\n",
    "        if study == 'study_25065_GPL96_MDACC-bmc15':\n",
    "            C = 1.72\n",
    "        model = svm.SVC(C=C, kernel='rbf', class_weight={1: (1 - numpy.mean(train_labels))  / numpy.mean(train_labels)})\n",
    "        # train the model\n",
    "        clf = model.fit(numpy.nan_to_num(train_data), numpy.nan_to_num(train_labels))\n",
    "        y_pred = clf.predict(numpy.nan_to_num(val_data))\n",
    "        # print(y_pred)\n",
    "        x_pred = clf.predict(numpy.nan_to_num(train_data))\n",
    "        compute_metrics(svm_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in svm_total:\n",
    "    ave = numpy.asarray(svm_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nearest neigbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_data, validation_data, train_labels):\n",
    "    tmp = []\n",
    "    for i in range(len(validation_data)):\n",
    "        diff = train_data - validation_data[i]\n",
    "        idx = numpy.argmin(numpy.sqrt(numpy.sum(diff ** 2, axis=1)))\n",
    "        tmp.append(idx)\n",
    "    return train_labels[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_total = defaultdict(list)\n",
    "for i in range(10):\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split()\n",
    "    y_pred = predict(numpy.nan_to_num(train_data), numpy.nan_to_num(val_data), train_labels)\n",
    "    # x_pred = predict(numpy.nan_to_num(train_data), numpy.nan_to_num(train_data), train_labels)\n",
    "    compute_metrics(nearest_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "\n",
    "for key in nearest_total:\n",
    "    ave = numpy.asarray(nearest_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(val_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "train_data, train_labels, val_data, val_labels, expected = random_split(ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_total = defaultdict(list)\n",
    "for i in range(10):\n",
    "    gnb = GaussianNB()\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split()\n",
    "    model = gnb.fit(numpy.nan_to_num(train_data, nan=-1), numpy.nan_to_num(train_labels))\n",
    "    y_pred = model.predict(numpy.nan_to_num(val_data, nan=-1))\n",
    "    x_pred = model.predict(numpy.nan_to_num(train_data))\n",
    "    compute_metrics(nearest_total, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "\n",
    "for key in nearest_total:\n",
    "    ave = numpy.asarray(nearest_total[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data = binarize_dataset(merged, genes_columns, feature_columns, to_letters=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin_data.drop('patient_ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test binarization by xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bin_data.dtypes[bin_data.dtypes == object].keys():\n",
    "    col_dict = {x: i for (i, x) in enumerate(sorted(set(bin_data[col])))}\n",
    "    bin_data[col] = bin_data[col].apply(lambda x: col_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "res = defaultdict(list)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    train_data, train_labels, val_data, val_labels, expected = random_split(bin_data, bmc,\n",
    "                                                                           feature_columns, label_columns)\n",
    "\n",
    "    # train the model\n",
    "    clf = model.fit(train_data, train_labels,\n",
    "                    eval_set=[(train_data, train_labels), (val_data, val_labels)], \n",
    "                    early_stopping_rounds=50, verbose=False)\n",
    "    y_pred = clf.predict(val_data)\n",
    "    x_pred = clf.predict(train_data)\n",
    "    compute_metrics(res, val_labels.flatten(), y_pred, train_labels, x_pred)\n",
    "for key in res:\n",
    "    ave = numpy.asarray(res[key]).mean(axis=0)\n",
    "    print('{0}: {1}'.format(key, ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_moses_features = ['posOutcome'] + feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data[subset_moses_features].to_csv('/tmp/cancer_bin_100.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = bin_data[subset_moses_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.columns[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_data[subset_moses_features[:30]].head(20).to_csv('/tmp/cancer_bin_100_small.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ar[0][-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[12 < 2 ** x for x in range(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for oth in other_columns:\n",
    "    print(oth)\n",
    "    print(set(digitize_non_genes_data(merged[oth])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(numpy.nan_to_num(merged.hormone_therapy, nan=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.histogram_bin_edges(r, bins=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_columns[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = numpy.histogram_bin_edges(r, bins=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# moses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencog.pyasmoses import moses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels, expected = random_split(ratio=0.1, to_numpy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna(-1)\n",
    "train_data.to_csv('/tmp/input_data.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_data.surgery_type.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = numpy.concatenate([train_labels[..., numpy.newaxis], train_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = moses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = \"--log-file log1.txt.log --hc-fraction-of-nn 0.01 -j5 --balance 1 -m 100000 --result-count 100 --reduct-knob-building-effort=2 --hc-widen-search=1 --enable-fs=1 --fs-algo=smd --fs-target-size=1000 --hc-crossover-min-neighbors=5000 --fs-focus=all --fs-seed=init  --hc-max-nn-evals=10000 --hc-crossover-pop-size=1000 -l debug --noise 0.2 -q 0.05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mos.run(input=numpy.nan_to_num(input_data), python=True, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = moses()\n",
    "input_data = [[0, 0, 0],\n",
    "              [0.2, 0.2, 0.4],\n",
    "              [1, 1, 2],\n",
    "              [1, 0, 1],\n",
    "              [2., 1, 3]]\n",
    "output = mos.run(input=input_data, python=True, args='-m 1000000 --max-time=60 --balance=1')\n",
    "print (output[0].score) # Prints: 0\n",
    "model = output[0].eval\n",
    "print(model([0, 1]))  # Returns: True\n",
    "print(model([1, 1]))  # Returns: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moses_args = []\n",
    "# target column\n",
    "moses_args.append('--problem_type=it')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
